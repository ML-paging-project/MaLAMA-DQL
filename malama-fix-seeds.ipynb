{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-03-23T17:01:47.562934Z",
     "iopub.status.busy": "2022-03-23T17:01:47.562438Z",
     "iopub.status.idle": "2022-03-23T17:01:49.416010Z",
     "shell.execute_reply": "2022-03-23T17:01:49.415253Z",
     "shell.execute_reply.started": "2022-03-23T17:01:47.562838Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import networkx as nx\n",
    "import random\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple, deque\n",
    "from itertools import count\n",
    "from PIL import Image\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "# if gpu is to be used\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-23T17:01:49.417803Z",
     "iopub.status.busy": "2022-03-23T17:01:49.417448Z",
     "iopub.status.idle": "2022-03-23T17:01:49.425049Z",
     "shell.execute_reply": "2022-03-23T17:01:49.424237Z",
     "shell.execute_reply.started": "2022-03-23T17:01:49.417775Z"
    }
   },
   "outputs": [],
   "source": [
    "def run_lru(cache_dict, cache_size, seq, start, box_width, hit_cost, miss_cost):   \n",
    "    i = start\n",
    "    remain_width = box_width\n",
    "    while remain_width>0:\n",
    "        if seq[i] in cache_dict.keys():\n",
    "            remain_width=remain_width-hit_cost\n",
    "            cache_dict.move_to_end(seq[i], last=False)\n",
    "        else:\n",
    "            remain_width=remain_width-miss_cost\n",
    "            cache_dict[seq[i]]=True\n",
    "            cache_dict.move_to_end(seq[i], last=False)\n",
    "            if len(cache_dict.keys())>cache_size:\n",
    "                cache_dict.popitem(last=True)\n",
    "        i = i+1\n",
    "        if i == len(seq):\n",
    "            break\n",
    "    return i # Where the box ends/The position of the next request in the sequence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-23T17:01:49.426479Z",
     "iopub.status.busy": "2022-03-23T17:01:49.426155Z",
     "iopub.status.idle": "2022-03-23T17:01:49.441320Z",
     "shell.execute_reply": "2022-03-23T17:01:49.440537Z",
     "shell.execute_reply.started": "2022-03-23T17:01:49.426435Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_vector(seq, pointer_position, window_size):\n",
    "    vector = []\n",
    "    if pointer_position == 0:\n",
    "        for i in range(window_size + 4):\n",
    "            vector.append(0.00)\n",
    "    else:\n",
    "        if pointer_position < window_size:\n",
    "            window = seq[0:pointer_position]\n",
    "        else:\n",
    "            window = seq[pointer_position - window_size:pointer_position]\n",
    "        frequency = {}\n",
    "        distinct = {}\n",
    "        segs_distinct = [0.00, 0.00, 0.00, 0.00] # chop the window into 4 segments \n",
    "        #count how many distinct page ids in each seg \n",
    "        \n",
    "        i=0\n",
    "        seg_id = 0\n",
    "        while i < len(window):\n",
    "            if window[i] in frequency.keys():\n",
    "                frequency[window[i]] = frequency[window[i]] + 1.00\n",
    "            else:\n",
    "                frequency[window[i]] = 1.00\n",
    "            distinct[window[i]] = True\n",
    "            if (i+1) % (int(window_size / 4)) == 0:\n",
    "                segs_distinct[seg_id] = len(distinct.keys())\n",
    "                distinct = {}\n",
    "                seg_id = seg_id + 1\n",
    "            i = i + 1\n",
    "        \n",
    "        if len(distinct.keys()) > 0:\n",
    "            segs_distinct[seg_id] = len(distinct.keys())\n",
    "        \n",
    "        # 1<=j<=w, the j-th variable of the vector is the frequency of the j-th most frequent page id in \n",
    "        # the window\n",
    "        for v in frequency.values():\n",
    "            vector.append(v)\n",
    "        while len(vector) < window_size:\n",
    "            vector.append(0)\n",
    "        vector.sort(reverse=True)\n",
    "        \n",
    "        # We chop the w requests into four segments of length w/4. \n",
    "        # Count how many distinct ids in each segment, and put the countings in the last four variables.\n",
    "        for v in segs_distinct:\n",
    "            vector.append(v)\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-23T17:01:49.444559Z",
     "iopub.status.busy": "2022-03-23T17:01:49.443608Z",
     "iopub.status.idle": "2022-03-23T17:01:49.461076Z",
     "shell.execute_reply": "2022-03-23T17:01:49.459924Z",
     "shell.execute_reply.started": "2022-03-23T17:01:49.444512Z"
    }
   },
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "    def __init__(self, window_size, num_of_box_kind):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(window_size+4, 512, 1)\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2)\n",
    "        self.conv2 = nn.Conv1d(256, 128, 1)\n",
    "        self.fc1 = nn.Linear(64, 32)\n",
    "        self.fc2 = nn.Linear(32, num_of_box_kind)\n",
    "        # print('.........'+str(num_of_box_kind))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.pool(torch.transpose(x,1,2))\n",
    "        x = self.conv2(torch.transpose(x,1,2))\n",
    "        x = self.pool(torch.transpose(x,1,2))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-23T17:01:49.462683Z",
     "iopub.status.busy": "2022-03-23T17:01:49.462313Z",
     "iopub.status.idle": "2022-03-23T17:01:49.480770Z",
     "shell.execute_reply": "2022-03-23T17:01:49.479886Z",
     "shell.execute_reply.started": "2022-03-23T17:01:49.462647Z"
    }
   },
   "outputs": [],
   "source": [
    "Transition = namedtuple('Transition', ('state', 'action', 'next_state', 'reward'))\n",
    "\n",
    "\n",
    "class ReplayMemory(object):\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        self.memory = deque([],maxlen=capacity)\n",
    "\n",
    "    def push(self, *args):\n",
    "        \"\"\"Save a transition\"\"\"\n",
    "        self.memory.append(Transition(*args))\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-23T17:01:49.482380Z",
     "iopub.status.busy": "2022-03-23T17:01:49.481842Z",
     "iopub.status.idle": "2022-03-23T17:01:49.497880Z",
     "shell.execute_reply": "2022-03-23T17:01:49.497063Z",
     "shell.execute_reply.started": "2022-03-23T17:01:49.482349Z"
    }
   },
   "outputs": [],
   "source": [
    "# Maverick: I add a no_more_random. \n",
    "# In the final epochs of training, I can choose to ban the model from acting randomly.\n",
    "# Guarantee the model converge.\n",
    "def select_action(state, steps_done, EPS_START, EPS_END, \n",
    "                  EPS_DECAY, no_more_random, num_of_box_kinds):\n",
    "    sample = random.random()\n",
    "    eps_threshold = EPS_END + (EPS_START - EPS_END) * math.exp(-1. * steps_done / EPS_DECAY)\n",
    "    steps_done += 1\n",
    "    if sample > eps_threshold or no_more_random:\n",
    "        with torch.no_grad():\n",
    "            # t.max(1) will return largest column value of each row.\n",
    "            # second column on max result is index of where max element was\n",
    "            # found, so we pick action with the larger expected reward.\n",
    "            return torch.argmax(policy_net(state)), steps_done\n",
    "    else:\n",
    "        return torch.tensor([[random.randrange(num_of_box_kinds)]], device=device, dtype=torch.long), steps_done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-23T17:01:49.499625Z",
     "iopub.status.busy": "2022-03-23T17:01:49.499155Z",
     "iopub.status.idle": "2022-03-23T17:01:49.514895Z",
     "shell.execute_reply": "2022-03-23T17:01:49.514076Z",
     "shell.execute_reply.started": "2022-03-23T17:01:49.499587Z"
    }
   },
   "outputs": [],
   "source": [
    "def optimize_model(memory, BATCH_SIZE, ALPHA, GAMMA, policy_net, optimizer):\n",
    "    if len(memory) < BATCH_SIZE:\n",
    "        return policy_net, optimizer\n",
    "    transitions = memory.sample(BATCH_SIZE)\n",
    "    # Transpose the batch (see https://stackoverflow.com/a/19343/3343043 for\n",
    "    # detailed explanation). This converts batch-array of Transitions\n",
    "    # to Transition of batch-arrays.\n",
    "    batch = Transition(*zip(*transitions))\n",
    "\n",
    "    # Compute a mask of non-final states and concatenate the batch elements\n",
    "    # (a final state would've been the one after which simulation ended)\n",
    "    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n",
    "                                          batch.next_state)), device=device, dtype=torch.bool)\n",
    "    non_final_next_states = torch.cat([s for s in batch.next_state\n",
    "                                                if s is not None])\n",
    "    state_batch = torch.cat(batch.state)\n",
    "    action_batch = torch.cat(batch.action)\n",
    "    reward_batch = torch.cat(batch.reward)\n",
    "\n",
    "    # Compute Q(s_t, a) - the model computes Q(s_t), then we select the\n",
    "    # columns of actions taken. These are the actions which would've been taken\n",
    "    # for each batch state according to policy_net\n",
    "    #print(state_batch.shape)\n",
    "    state_action_values = policy_net(state_batch).gather(0, action_batch)\n",
    "\n",
    "    # Compute V(s_{t+1}) for all next states.\n",
    "    # Expected values of actions for non_final_next_states are computed based\n",
    "    # on the \"older\" target_net; selecting their best reward with max(1)[0].\n",
    "    # This is merged based on the mask, such that we'll have either the expected\n",
    "    # state value or 0 in case the state was final.\n",
    "    next_state_values = torch.zeros(BATCH_SIZE, device=device)\n",
    "    nsv=target_net(non_final_next_states).max(1)[0].detach()\n",
    "    lst=[]\n",
    "    for row in nsv:\n",
    "        lst.append(torch.argmax(row)*1.00)\n",
    "    next_state_values[non_final_mask] = torch.tensor(lst,device=device)\n",
    "    # Compute the expected Q values\n",
    "    \n",
    "    ##############################################\n",
    "    ## Maverick: I add learning rate ALPHA here ##\n",
    "    ##############################################\n",
    "    expected_state_action_values = ALPHA*((next_state_values * GAMMA) + reward_batch)\n",
    "\n",
    "    # Compute Huber loss\n",
    "    criterion = nn.SmoothL1Loss()\n",
    "    loss = criterion(state_action_values, expected_state_action_values.unsqueeze(1))\n",
    "\n",
    "    # Optimize the model\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    for param in policy_net.parameters():\n",
    "        param.grad.data.clamp_(-1, 1)\n",
    "    optimizer.step()\n",
    "    return policy_net, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-23T17:01:49.516488Z",
     "iopub.status.busy": "2022-03-23T17:01:49.516132Z",
     "iopub.status.idle": "2022-03-23T17:01:49.607098Z",
     "shell.execute_reply": "2022-03-23T17:01:49.605938Z",
     "shell.execute_reply.started": "2022-03-23T17:01:49.516442Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '1000', '0', '1999', '1000', '1999', '1999', '0', '0', '0']\n",
      "400961\n"
     ]
    }
   ],
   "source": [
    "f = open(\"seq-sort10k.ssv\")\n",
    "data = f.readline()\n",
    "seq=data.split(' ')\n",
    "print(seq[:10])\n",
    "print(len(seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-23T17:01:49.608814Z",
     "iopub.status.busy": "2022-03-23T17:01:49.608383Z",
     "iopub.status.idle": "2022-03-23T17:01:49.614664Z",
     "shell.execute_reply": "2022-03-23T17:01:49.613647Z",
     "shell.execute_reply.started": "2022-03-23T17:01:49.608778Z"
    }
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8\n",
    "GAMMA = 0.3\n",
    "EPS_START = 0.9\n",
    "EPS_END = 0.00001\n",
    "EPS_DECAY = 500\n",
    "TARGET_UPDATE = 5\n",
    "window_size=256\n",
    "miss_cost = 100 ##################\n",
    "# number_of_box_kinds = min(8,math.ceil(math.log2(miss_cost))) #############\n",
    "number_of_box_kinds=8\n",
    "NUMBER_OF_MODELS = 5 # Train several models, choose the best\n",
    "num_episodes = 10\n",
    "ALPHA = 0.8 # Learning rate #########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-23T17:01:49.617305Z",
     "iopub.status.busy": "2022-03-23T17:01:49.616878Z",
     "iopub.status.idle": "2022-03-23T17:04:02.186964Z",
     "shell.execute_reply": "2022-03-23T17:04:02.185693Z",
     "shell.execute_reply.started": "2022-03-23T17:01:49.617251Z"
    }
   },
   "outputs": [],
   "source": [
    "features = []\n",
    "for i in range(len(seq)):\n",
    "    features.append(get_vector(seq, i, window_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-23T17:57:55.279857Z",
     "iopub.status.busy": "2022-03-23T17:57:55.279552Z",
     "iopub.status.idle": "2022-03-23T18:13:36.792256Z",
     "shell.execute_reply": "2022-03-23T18:13:36.790332Z",
     "shell.execute_reply.started": "2022-03-23T17:57:55.279821Z"
    }
   },
   "outputs": [],
   "source": [
    "best_result=[math.inf for _ in range(num_episodes)]\n",
    "best_hist = [0 for _ in range(number_of_box_kinds)]\n",
    "print(len(best_result))\n",
    "best_policy_net = DQN(window_size,number_of_box_kinds).to(device)\n",
    "best_target_net = DQN(window_size,number_of_box_kinds).to(device)\n",
    "best_seeds=DQN(window_size,number_of_box_kinds).to(device)\n",
    "\n",
    "for model in range(NUMBER_OF_MODELS):\n",
    "    global_lru=collections.OrderedDict()\n",
    "    steps_done = 0\n",
    "    policy_net = DQN(window_size,number_of_box_kinds).to(device)\n",
    "    target_net = DQN(window_size,number_of_box_kinds).to(device)\n",
    "    target_net.load_state_dict(policy_net.state_dict())\n",
    "    target_net.eval()\n",
    "    seeds=DQN(window_size,number_of_box_kinds).to(device)\n",
    "    seeds.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "    optimizer = optim.RMSprop(policy_net.parameters())\n",
    "    memory = ReplayMemory(10000)\n",
    "    result = []\n",
    "    hist = [0 for _ in range(number_of_box_kinds)] \n",
    "\n",
    "    for i_episode in range(num_episodes):\n",
    "        for xx in range(number_of_box_kinds):\n",
    "            hist[xx]=0\n",
    "        pointer = 0\n",
    "        impact = 0\n",
    "        while pointer < len(seq):\n",
    "            startpointer = pointer\n",
    "            state = features[pointer]\n",
    "            state = torch.tensor([[state]], device=device)\n",
    "            state = torch.transpose(state,1,2)\n",
    "            action, steps_done = select_action(state,steps_done,EPS_START,EPS_END,EPS_DECAY,\n",
    "                                               (i_episode+1)/num_episodes>0.9,number_of_box_kinds)\n",
    "            box_id=action\n",
    "            # print(box_id)\n",
    "            hist[box_id]=hist[box_id]+1\n",
    "            cache_size=2**box_id\n",
    "            box_width = miss_cost*cache_size\n",
    "            \n",
    "            # Compartmentalization\n",
    "            # Load top pages from LRU stack.\n",
    "            mycache = collections.OrderedDict()\n",
    "            for pid in global_lru.keys():\n",
    "                mycache[pid]=True\n",
    "                mycache.move_to_end(pid, last=True)###########\n",
    "                if len(mycache)==cache_size:\n",
    "                    break\n",
    "\n",
    "            action = torch.tensor([[[action]]], device=device) # make it a tensor\n",
    "            pointer =run_lru(mycache, cache_size, seq, pointer, box_width, 1, miss_cost)\n",
    "            endpointer = pointer\n",
    "            \n",
    "            # Update global stack\n",
    "            for x in range(startpointer, endpointer):\n",
    "                if seq[x] in global_lru.keys():\n",
    "                    global_lru.move_to_end(seq[x], last=False)\n",
    "                else:\n",
    "                    global_lru[seq[x]]=True\n",
    "                    global_lru.move_to_end(seq[x], last=False)\n",
    "                    \n",
    "            # print(mi)\n",
    "            area = 3*miss_cost*cache_size*cache_size\n",
    "            impact=impact+area\n",
    "            reward = torch.tensor([[[-area]]], device=device)\n",
    "\n",
    "            if pointer < len(seq):\n",
    "                next_state = features[pointer]\n",
    "                next_state = torch.tensor([[next_state]], device=device)\n",
    "                next_state = torch.transpose(next_state,1,2)\n",
    "            else:\n",
    "                next_state = None\n",
    "\n",
    "            # Store the transition in memory\n",
    "            memory.push(state, action, next_state, reward)\n",
    "\n",
    "            # Move to the next state\n",
    "            state = next_state\n",
    "\n",
    "            # Perform one step of the optimization (on the policy network)\n",
    "            policy_net, optimizer=optimize_model(memory, BATCH_SIZE, ALPHA, GAMMA, policy_net, optimizer)\n",
    "\n",
    "        # Update the target network, copying all weights and biases in DQN\n",
    "        clear_output()\n",
    "        print(best_result[-1])\n",
    "        print('MODEL-'+str(model))\n",
    "        print('epoch='+str(i_episode)+'..........impact='+str(impact))\n",
    "        result.append(impact.item())\n",
    "\n",
    "\n",
    "        if i_episode % TARGET_UPDATE == 0:\n",
    "            target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "    print('Complete')\n",
    "    if result[-1]<best_result[-1]:\n",
    "        best_seeds.load_state_dict(seeds.state_dict())\n",
    "        for idx in range(len(result)):\n",
    "            best_result[idx]=result[idx]\n",
    "        for idx in range(len(hist)):\n",
    "            best_hist[idx]=hist[idx]\n",
    "            \n",
    "        # store the best for further use\n",
    "        best_policy_net.load_state_dict(policy_net.state_dict())\n",
    "        best_target_net.load_state_dict(target_net.state_dict())\n",
    "        \n",
    "print(best_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-23T18:13:47.684002Z",
     "iopub.status.busy": "2022-03-23T18:13:47.683639Z",
     "iopub.status.idle": "2022-03-23T18:13:47.693507Z",
     "shell.execute_reply": "2022-03-23T18:13:47.692315Z",
     "shell.execute_reply.started": "2022-03-23T18:13:47.683972Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save({'seeds':best_seeds.state_dict()}, './best_seeds.t7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-23T18:14:05.135618Z",
     "iopub.status.busy": "2022-03-23T18:14:05.135302Z",
     "iopub.status.idle": "2022-03-23T18:24:53.912197Z",
     "shell.execute_reply": "2022-03-23T18:24:53.910371Z",
     "shell.execute_reply.started": "2022-03-23T18:14:05.135587Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0..........impact=tensor([[333387000]], device='cuda:0')\n",
      "epoch=1..........impact=tensor([[45029100]], device='cuda:0')\n",
      "epoch=2..........impact=tensor(34104000, device='cuda:0')\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\TIANCH~1\\AppData\\Local\\Temp/ipykernel_707240/3126216201.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[0maction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# make it a tensor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m         \u001b[0mpointer\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mrun_lru\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmycache\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcache_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpointer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbox_width\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmiss_cost\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m         \u001b[0mendpointer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpointer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\TIANCH~1\\AppData\\Local\\Temp/ipykernel_707240/1393932241.py\u001b[0m in \u001b[0;36mrun_lru\u001b[1;34m(cache_dict, cache_size, seq, start, box_width, hit_cost, miss_cost)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mremain_width\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbox_width\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[1;32mwhile\u001b[0m \u001b[0mremain_width\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mseq\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcache_dict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m             \u001b[0mremain_width\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mremain_width\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mhit_cost\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "global_lru=collections.OrderedDict()\n",
    "steps_done = 0\n",
    "bs = torch.load('best_seeds.t7')\n",
    "policy_net = DQN(window_size,number_of_box_kinds).to(device)\n",
    "policy_net.load_state_dict(bs['seeds'])\n",
    "target_net = DQN(window_size,number_of_box_kinds).to(device)\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "target_net.eval()\n",
    "\n",
    "optimizer = optim.RMSprop(policy_net.parameters())\n",
    "memory = ReplayMemory(10000)\n",
    "result = []\n",
    "\n",
    "for i_episode in range(num_episodes):\n",
    "    pointer = 0\n",
    "    impact = 0\n",
    "    while pointer < len(seq):\n",
    "        startpointer = pointer\n",
    "        state = features[pointer]\n",
    "        state = torch.tensor([[state]], device=device)\n",
    "        state = torch.transpose(state,1,2)\n",
    "        action, steps_done = select_action(state,steps_done,EPS_START,EPS_END,EPS_DECAY,\n",
    "                                           (i_episode+1)/num_episodes>0.9,number_of_box_kinds)\n",
    "        box_id=action\n",
    "        cache_size=2**box_id\n",
    "        box_width = miss_cost*cache_size\n",
    "\n",
    "        # Compartmentalization\n",
    "        # Load top pages from LRU stack.\n",
    "        mycache = collections.OrderedDict()\n",
    "        for pid in global_lru.keys():\n",
    "            mycache[pid]=True\n",
    "            mycache.move_to_end(pid, last=True)###########\n",
    "            if len(mycache)==cache_size:\n",
    "                break\n",
    "\n",
    "        action = torch.tensor([[[action]]], device=device) # make it a tensor\n",
    "        pointer =run_lru(mycache, cache_size, seq, pointer, box_width, 1, miss_cost)\n",
    "        endpointer = pointer\n",
    "\n",
    "        # Update global stack\n",
    "        for x in range(startpointer, endpointer):\n",
    "            if seq[x] in global_lru.keys():\n",
    "                global_lru.move_to_end(seq[x], last=False)\n",
    "            else:\n",
    "                global_lru[seq[x]]=True\n",
    "                global_lru.move_to_end(seq[x], last=False)\n",
    "\n",
    "        # print(mi)\n",
    "        area = 3*miss_cost*cache_size*cache_size\n",
    "        impact=impact+area\n",
    "        reward = torch.tensor([[[-area]]], device=device)\n",
    "\n",
    "        if pointer < len(seq):\n",
    "            next_state = features[pointer]\n",
    "            next_state = torch.tensor([[next_state]], device=device)\n",
    "            next_state = torch.transpose(next_state,1,2)\n",
    "        else:\n",
    "            next_state = None\n",
    "\n",
    "        # Store the transition in memory\n",
    "        memory.push(state, action, next_state, reward)\n",
    "\n",
    "        # Move to the next state\n",
    "        state = next_state\n",
    "\n",
    "        # Perform one step of the optimization (on the policy network)\n",
    "        policy_net, optimizer=optimize_model(memory, BATCH_SIZE, ALPHA, GAMMA, policy_net, optimizer)\n",
    "\n",
    "    # Update the target network, copying all weights and biases in DQN\n",
    "    #clear_output()\n",
    "    #print(best_result[-1])\n",
    "    print('epoch='+str(i_episode)+'..........impact='+str(impact))\n",
    "    result.append(impact.item())\n",
    "\n",
    "\n",
    "    if i_episode % TARGET_UPDATE == 0:\n",
    "        target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "print('Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-23T18:26:46.547528Z",
     "iopub.status.busy": "2022-03-23T18:26:46.547200Z"
    }
   },
   "outputs": [],
   "source": [
    "while True:\n",
    "    clear_output()\n",
    "    print('hello')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
